{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyaAls777/opencvAI-workshop/blob/main/AIVision101_OpenCV_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting Up a Virtual Environment in VS Code\n"
      ],
      "metadata": {
        "id": "Nc2Scg7osI2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Follow these steps to set up your virtual environment using *Visual Studio Code*:\n",
        "\n",
        "\n",
        "**1. Create a Project Folder**\n",
        "\n",
        "1. Open *VS Code*.\n",
        "2. Go to File > Open Folder...\n",
        "3. Choose or create a folder for your project.\n",
        "\n",
        "\n",
        "**2. Open the Terminal**\n",
        "\n",
        "1. Go to Terminal > New Terminal\n",
        "2. Or use the shortcut:\n",
        "\n",
        "   * *Windows*: Ctrl + backtick ( \\` )\n",
        "   * *macOS*: Cmd + backtick ( \\` )\n",
        "\n",
        "\n",
        "**3. Create a Virtual Environment**\n",
        "\n",
        "In the terminal, run the following:\n",
        "\n",
        "* *Windows*:\n"
      ],
      "metadata": {
        "id": "cMomOpghu0dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python -m venv techclubisthebest\n"
      ],
      "metadata": {
        "id": "lCRF-aIosK9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *macOS*:\n"
      ],
      "metadata": {
        "id": "NvPUxzTzsNQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python3 -m venv techclubisthebest"
      ],
      "metadata": {
        "id": "LOoB4qvasQvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will create a folder named techclubisthebest containing your isolated virtual environment."
      ],
      "metadata": {
        "id": "cwxl7nmFvS--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Activate the Virtual Environment\n"
      ],
      "metadata": {
        "id": "OE1lKTYUsZah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *Windows*:\n"
      ],
      "metadata": {
        "id": "umHHCm5VsntG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ".\\techclubisthebest\\Scripts\\activate"
      ],
      "metadata": {
        "id": "WJF6zkkssmnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *macOS*:\n"
      ],
      "metadata": {
        "id": "bhXKH5-6sqUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source techclubisthebest/bin/activate"
      ],
      "metadata": {
        "id": "gbR35NnFssdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You‚Äôll know the environment is activated when you see this at the beginning of your terminal:\n",
        "\n",
        "\n",
        "(techclubisthebest)\n",
        "\n",
        "\n",
        "\n",
        "You‚Äôre now ready to install dependencies and start coding inside your isolated¬†environment"
      ],
      "metadata": {
        "id": "TOaIGrW_s0Ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####AI Vision 101: OpenCV\n",
        "\n",
        "Install Requried Libraries"
      ],
      "metadata": {
        "id": "227FY_AYLkOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface opencv-python-headless tf-keras"
      ],
      "metadata": {
        "id": "2rJNhATzLabC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stage 1"
      ],
      "metadata": {
        "id": "T8VRrMfjgDy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "wyTeZBMdLvxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "8FYoaw05L2FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Webcam"
      ],
      "metadata": {
        "id": "M1xaxm4zL9UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Open the webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not access the webcam.\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "id": "o4gxkTs2f9rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Show camera feed in a loop\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    cv2.imshow(\"Webcam Feed\", frame)\n",
        "\n",
        "    # Press 'q' to quit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQqrEE0wMC8D",
        "outputId": "a16fdca6-2e38-4228-f132-35f88ab6ba6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not access the webcam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Cleanup\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "BObVbwWigCLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stage 2"
      ],
      "metadata": {
        "id": "EILn4SAvgFzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "F0BR476DgLnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Webcam"
      ],
      "metadata": {
        "id": "r3yxCIGagLnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not access the webcam.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16fdca6-2e38-4228-f132-35f88ab6ba6b",
        "id": "oSWQ1z4tgLnC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not access the webcam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Initial States"
      ],
      "metadata": {
        "id": "oIP_zUbJSiW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_mode = 'normal'\n",
        "snapshot_count = 0"
      ],
      "metadata": {
        "id": "Oar863h-Sobf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print Instructions"
      ],
      "metadata": {
        "id": "bHoHmBk0Su9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "Press keys to switch filters:\n",
        "g - Grayscale\n",
        "e - Edge Detection\n",
        "b - Blur\n",
        "k - Sketch\n",
        "c - Cartoon\n",
        "i - Invert Colors\n",
        "s - Shapes & Text\n",
        "p - Save Snapshot\n",
        "n - Normal\n",
        "q - Quit\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "gby6BgdwSzf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ac786b-3074-4503-e532-2df2802429af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Press keys to switch filters:\n",
            "g - Grayscale\n",
            "e - Edge Detection\n",
            "b - Blur\n",
            "k - Sketch\n",
            "c - Cartoon\n",
            "i - Invert Colors\n",
            "s - Shapes & Text\n",
            "m - Emotion-Based Filter (DeepFace)\n",
            "p - Save Snapshot\n",
            "n - Normal\n",
            "q - Quit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Video Capture Loop"
      ],
      "metadata": {
        "id": "_uPTLy7QS1co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    output = frame.copy()"
      ],
      "metadata": {
        "id": "HcOumiPVS3aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the Selected Filter\n",
        "(Each time a new video frame is captured, it checks the selected filter)"
      ],
      "metadata": {
        "id": "jMfK_tTEk-LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Turns the image black and white.\n",
        "if filter_mode == 'gray':\n",
        "  output = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#Highlights only the edges (like outlines of objects).\n",
        "elif filter_mode == 'edges':\n",
        "  output = cv2.Canny(frame, 100, 200)\n",
        "\n",
        "#Makes the image soft and blurry.\n",
        "elif filter_mode == 'blur':\n",
        "  output = cv2.GaussianBlur(frame, (15, 15), 0)\n",
        "\n",
        "#Makes it look like a pencil drawing using grayscale and blur.\n",
        "elif filter_mode == 'sketch':\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  inv = 255 - gray\n",
        "  blur = cv2.GaussianBlur(inv, (21, 21), 0)\n",
        "  inv_blur = 255 - blur\n",
        "  output = cv2.divide(gray, inv_blur, scale=256.0)\n",
        "\n",
        "#Keeps colors but simplifies them and adds dark outlines to make it look like a cartoon.\n",
        "elif filter_mode == 'cartoon':\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  blur = cv2.medianBlur(gray, 7)\n",
        "  edges = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                cv2.THRESH_BINARY, 9, 10)\n",
        "  color = cv2.bilateralFilter(frame, 9, 300, 300)\n",
        "  output = cv2.bitwise_and(color, color, mask=edges)\n",
        "\n",
        "#Flips the colors (like turning white to black and vice versa).\n",
        "elif filter_mode == 'invert':\n",
        "  output = cv2.bitwise_not(frame)\n",
        "\n",
        "#Draws a rectangle, a circle, and some text on top of the video.\n",
        "elif filter_mode == 'shapes':\n",
        "  height, width = output.shape[:2]\n",
        "  cv2.rectangle(output, (50, 50), (width - 50, height - 50), (0, 255, 0), 3)\n",
        "  cv2.circle(output, (width // 2, height // 2), 100, (255, 0, 0), 5)\n",
        "  cv2.putText(output, 'OpenCV Workshop', (60, height - 60),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n"
      ],
      "metadata": {
        "id": "YdXKRmnJk-mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the Frame (Displays the video with the selected effect.)"
      ],
      "metadata": {
        "id": "nb-DUuh9qSfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imshow(\"Webcam Filter\", output)"
      ],
      "metadata": {
        "id": "Ogm70VnpqV17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Keyboard Input (Check Keyboard Input)"
      ],
      "metadata": {
        "id": "roHw2xwJqbJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = cv2.waitKey(1) & 0xFF\n",
        "    if key == ord('q'):\n",
        "        break\n",
        "    elif key == ord('g'):\n",
        "        filter_mode = 'gray'\n",
        "    elif key == ord('e'):\n",
        "        filter_mode = 'edges'\n",
        "    elif key == ord('b'):\n",
        "        filter_mode = 'blur'\n",
        "    elif key == ord('k'):\n",
        "        filter_mode = 'sketch'\n",
        "    elif key == ord('c'):\n",
        "        filter_mode = 'cartoon'\n",
        "    elif key == ord('i'):\n",
        "        filter_mode = 'invert'\n",
        "    elif key == ord('s'):\n",
        "      filter_mode = 'shapes'\n",
        "    elif key == ord('n'):\n",
        "        filter_mode = 'normal'\n"
      ],
      "metadata": {
        "id": "h6tCjCyIqprS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exit and Clean Up"
      ],
      "metadata": {
        "id": "kqo_C2oyrzYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Stops the webcam and closes the window when you press q.\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "HynDJWsVq-Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stage 3"
      ],
      "metadata": {
        "id": "RPxWAyDBgz7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from deepface import DeepFace"
      ],
      "metadata": {
        "id": "8Xk9yOEAg_BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Webcam"
      ],
      "metadata": {
        "id": "QWm_nu-Bg_Be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not access the webcam.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16fdca6-2e38-4228-f132-35f88ab6ba6b",
        "id": "VUv0iYi3g_Be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not access the webcam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Initial States"
      ],
      "metadata": {
        "id": "WY5neaCig_Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_mode = 'normal'\n",
        "snapshot_count = 0"
      ],
      "metadata": {
        "id": "ziFhKmyPg_Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Face Detection Model"
      ],
      "metadata": {
        "id": "sBp_Z3PjSq05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
      ],
      "metadata": {
        "id": "N8wCPQD-Ssxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print Instructions"
      ],
      "metadata": {
        "id": "ExWj6yUvg_Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "Press keys to switch filters:\n",
        "g - Grayscale\n",
        "e - Edge Detection\n",
        "b - Blur\n",
        "k - Sketch\n",
        "c - Cartoon\n",
        "i - Invert Colors\n",
        "s - Shapes & Text\n",
        "m - Emotion-Based Filter (DeepFace)\n",
        "p - Save Snapshot\n",
        "n - Normal\n",
        "q - Quit\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ac786b-3074-4503-e532-2df2802429af",
        "id": "mBDkyG7Jg_Bg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Press keys to switch filters:\n",
            "g - Grayscale\n",
            "e - Edge Detection\n",
            "b - Blur\n",
            "k - Sketch\n",
            "c - Cartoon\n",
            "i - Invert Colors\n",
            "s - Shapes & Text\n",
            "m - Emotion-Based Filter (DeepFace)\n",
            "p - Save Snapshot\n",
            "n - Normal\n",
            "q - Quit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Video Capture Loop"
      ],
      "metadata": {
        "id": "H6aj1ONWg_Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    output = frame.copy()"
      ],
      "metadata": {
        "id": "vmb0g9UWg_Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the Selected Filter\n",
        "(Each time a new video frame is captured, it checks the selected filter)"
      ],
      "metadata": {
        "id": "U4N8z5PLg_Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Turns the image black and white.\n",
        "if filter_mode == 'gray':\n",
        "  output = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#Highlights only the edges (like outlines of objects).\n",
        "elif filter_mode == 'edges':\n",
        "  output = cv2.Canny(frame, 100, 200)\n",
        "\n",
        "#Makes the image soft and blurry.\n",
        "elif filter_mode == 'blur':\n",
        "  output = cv2.GaussianBlur(frame, (15, 15), 0)\n",
        "\n",
        "#Makes it look like a pencil drawing using grayscale and blur.\n",
        "elif filter_mode == 'sketch':\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  inv = 255 - gray\n",
        "  blur = cv2.GaussianBlur(inv, (21, 21), 0)\n",
        "  inv_blur = 255 - blur\n",
        "  output = cv2.divide(gray, inv_blur, scale=256.0)\n",
        "\n",
        "#Keeps colors but simplifies them and adds dark outlines to make it look like a cartoon.\n",
        "elif filter_mode == 'cartoon':\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  blur = cv2.medianBlur(gray, 7)\n",
        "  edges = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                cv2.THRESH_BINARY, 9, 10)\n",
        "  color = cv2.bilateralFilter(frame, 9, 300, 300)\n",
        "  output = cv2.bitwise_and(color, color, mask=edges)\n",
        "\n",
        "#Flips the colors (like turning white to black and vice versa).\n",
        "elif filter_mode == 'invert':\n",
        "  output = cv2.bitwise_not(frame)\n",
        "\n",
        "#Draws a rectangle, a circle, and some text on top of the video.\n",
        "elif filter_mode == 'shapes':\n",
        "  height, width = output.shape[:2]\n",
        "  cv2.rectangle(output, (50, 50), (width - 50, height - 50), (0, 255, 0), 3)\n",
        "  cv2.circle(output, (width // 2, height // 2), 100, (255, 0, 0), 5)\n",
        "  cv2.putText(output, 'OpenCV Workshop', (60, height - 60),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
        "\n",
        "#Important\n",
        "#Detects faces in the frame, and then Applies\n",
        "#different filters depending on the emotion.\n",
        "#For example: Happy ‚Üí edges / Sad ‚Üí blur / Angry ‚Üí inverted colors\n",
        "elif filter_mode == 'emotion':\n",
        "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "  faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
        "\n",
        "  for x, y, w, h in faces:\n",
        "    face_roi = frame[y:y + h, x:x + w]\n",
        "    try:\n",
        "        result = DeepFace.analyze(face_roi, actions=[\"emotion\"], enforce_detection=False)\n",
        "        emotion = result[0][\"dominant_emotion\"]\n",
        "    except Exception as e:\n",
        "        emotion = \"unknown\"\n",
        "\n",
        "  if emotion == \"happy\":\n",
        "    filtered_face = cv2.Canny(face_roi, 100, 200)\n",
        "  elif emotion == \"angry\":\n",
        "    filtered_face = cv2.bitwise_not(face_roi)\n",
        "  elif emotion == \"sad\":\n",
        "    filtered_face = cv2.GaussianBlur(face_roi, (15, 15), 0)\n",
        "  else:\n",
        "    filtered_face = face_roi\n",
        "\n",
        "  if len(filtered_face.shape) == 2:\n",
        "    filtered_face = cv2.cvtColor(filtered_face, cv2.COLOR_GRAY2BGR)\n",
        "  output[y:y + h, x:x + w] = cv2.convertScaleAbs(filtered_face)\n",
        "\n",
        "# Display emotion\n",
        "  cv2.putText(output, f\"{emotion}\", (x, y - 10),\n",
        "              cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)"
      ],
      "metadata": {
        "id": "MbKFfOleg_Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the Frame (Displays the video with the selected effect.)"
      ],
      "metadata": {
        "id": "jj3vZGZ-g_Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imshow(\"Webcam Filter\", output)"
      ],
      "metadata": {
        "id": "9OjmkjVmg_Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Keyboard Input (Check Keyboard Input)"
      ],
      "metadata": {
        "id": "XLEeRXX2g_Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Based on the key pressed (g, b, m and ...) it changes the filter\n",
        "key = cv2.waitKey(1) & 0xFF\n",
        "if key == ord('q'):\n",
        "    break\n",
        "elif key == ord('g'):\n",
        "    filter_mode = 'gray'\n",
        "elif key == ord('e'):\n",
        "    filter_mode = 'edges'\n",
        "elif key == ord('b'):\n",
        "    filter_mode = 'blur'\n",
        "elif key == ord('k'):\n",
        "    filter_mode = 'sketch'\n",
        "elif key == ord('c'):\n",
        "    filter_mode = 'cartoon'\n",
        "elif key == ord('i'):\n",
        "    filter_mode = 'invert'\n",
        "elif key == ord('s'):\n",
        "    filter_mode = 'shapes'\n",
        "elif key == ord('m'):\n",
        "    filter_mode = 'emotion'\n",
        "elif key == ord('n'):\n",
        "    filter_mode = 'normal'\n",
        "elif key == ord('p'):\n",
        "    filename = f'snapshot_{snapshot_count}.png'\n",
        "    if filter_mode in ['gray', 'edges', 'sketch']:\n",
        "        cv2.imwrite(filename, output)\n",
        "    else:\n",
        "        cv2.imwrite(filename, output)\n",
        "    print(f\"Snapshot saved as {filename}\")\n",
        "    snapshot_count += 1"
      ],
      "metadata": {
        "id": "pX9Kyn1Jg_Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exit and Clean Up"
      ],
      "metadata": {
        "id": "1xB36Wiqg_Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Stops the webcam and closes the window when you press q.\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "cKH4qlTqg_Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extra"
      ],
      "metadata": {
        "id": "qcxR2PvhmuoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pixelate_face(frame, x, y, w, h):\n",
        "    face_roi = frame[y : y + h, x : x + w]\n",
        "    small = cv2.resize(face_roi, (16, 16), interpolation=cv2.INTER_LINEAR)\n",
        "    pixelated = cv2.resize(small, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "    frame[y : y + h, x : x + w] = pixelated\n",
        "    return frame\n",
        "\n",
        "\n",
        "def thermal_face_filter(frame, x, y, w, h):\n",
        "    face_roi = frame[y : y + h, x : x + w]\n",
        "    gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
        "    thermal = cv2.applyColorMap(gray, cv2.COLORMAP_JET)\n",
        "    frame[y : y + h, x : x + w] = thermal\n",
        "    return frame"
      ],
      "metadata": {
        "id": "QHoX1nZnmxUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    elif filter_mode == \"thermal\":\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "        for x, y, w, h in faces:\n",
        "            output = thermal_face_filter(output, x, y, w, h)\n",
        "            cv2.putText(\n",
        "                output,\n",
        "                \"üî• Thermal Vision\",\n",
        "                (x, y - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.8,\n",
        "                (255, 255, 0),\n",
        "                2,\n",
        "            )\n",
        "    elif filter_mode == \"pixel\":\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "        for x, y, w, h in faces:\n",
        "            output = pixelate_face(output, x, y, w, h)\n",
        "            cv2.putText(\n",
        "                output,\n",
        "                \"ü§ê Privacy Please\",\n",
        "                (x, y - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.8,\n",
        "                (0, 0, 255),\n",
        "                2,\n",
        "            )\n"
      ],
      "metadata": {
        "id": "hyC1LxYJDyoE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}